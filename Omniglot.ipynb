{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\Data\\Omniglot\\python\\images_background\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFiles(path):\n",
    "    df = pd.DataFrame(columns=['filepath', 'language', 'character' ,'category'])\n",
    "    for language in os.listdir(path):\n",
    "        for character in os.listdir(\"{}\\{}\".format(path, language)):\n",
    "            for item in os.listdir(\"{}\\{}\\{}\".format(path, language, character)):\n",
    "                df = df.append({'filepath':\"{}\\{}\\{}\\{}\".format(path, language, character, item), \n",
    "                                     'language':language, \n",
    "                                     'character': character, \n",
    "                                     'category': \"{}_{}\".format(language,character)}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = getFiles(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>language</th>\n",
       "      <th>character</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Data\\Omniglot\\python\\images_background\\Alph...</td>\n",
       "      <td>Alphabet_of_the_Magi</td>\n",
       "      <td>character01</td>\n",
       "      <td>Alphabet_of_the_Magi_character01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Data\\Omniglot\\python\\images_background\\Alph...</td>\n",
       "      <td>Alphabet_of_the_Magi</td>\n",
       "      <td>character01</td>\n",
       "      <td>Alphabet_of_the_Magi_character01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Data\\Omniglot\\python\\images_background\\Alph...</td>\n",
       "      <td>Alphabet_of_the_Magi</td>\n",
       "      <td>character01</td>\n",
       "      <td>Alphabet_of_the_Magi_character01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Data\\Omniglot\\python\\images_background\\Alph...</td>\n",
       "      <td>Alphabet_of_the_Magi</td>\n",
       "      <td>character01</td>\n",
       "      <td>Alphabet_of_the_Magi_character01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Data\\Omniglot\\python\\images_background\\Alph...</td>\n",
       "      <td>Alphabet_of_the_Magi</td>\n",
       "      <td>character01</td>\n",
       "      <td>Alphabet_of_the_Magi_character01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath              language  \\\n",
       "0  E:\\Data\\Omniglot\\python\\images_background\\Alph...  Alphabet_of_the_Magi   \n",
       "1  E:\\Data\\Omniglot\\python\\images_background\\Alph...  Alphabet_of_the_Magi   \n",
       "2  E:\\Data\\Omniglot\\python\\images_background\\Alph...  Alphabet_of_the_Magi   \n",
       "3  E:\\Data\\Omniglot\\python\\images_background\\Alph...  Alphabet_of_the_Magi   \n",
       "4  E:\\Data\\Omniglot\\python\\images_background\\Alph...  Alphabet_of_the_Magi   \n",
       "\n",
       "     character                          category  \n",
       "0  character01  Alphabet_of_the_Magi_character01  \n",
       "1  character01  Alphabet_of_the_Magi_character01  \n",
       "2  character01  Alphabet_of_the_Magi_character01  \n",
       "3  character01  Alphabet_of_the_Magi_character01  \n",
       "4  character01  Alphabet_of_the_Magi_character01  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['category'].factorize()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates Positive and Negative data based on anchor item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainingData(df, n):\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        anchorItem = df.sample()\n",
    "        #postive sample\n",
    "        positiveItem = df[(df['label'] == anchorItem['label'].item()) & (df['filepath'] != anchorItem['filepath'].item())].sample()\n",
    "        data.append({\"anchor\":anchorItem.index.item(), \"item\":positiveItem.index.item(), \"label\":1.0})\n",
    "        #negative sample\n",
    "        negativeItem = df[df['label'] != anchorItem['label'].item()].sample()\n",
    "        data.append({\"anchor\":anchorItem.index.item(), \"item\":negativeItem.index.item(), \"label\":0.0})\n",
    "        \n",
    "    return pd.DataFrame(data)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generateTrainingData(df, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor</th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2452</td>\n",
       "      <td>2451</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2452</td>\n",
       "      <td>5401</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11320</td>\n",
       "      <td>11331</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11320</td>\n",
       "      <td>3358</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14027</td>\n",
       "      <td>14024</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anchor   item  label\n",
       "0    2452   2451    1.0\n",
       "1    2452   5401    0.0\n",
       "2   11320  11331    1.0\n",
       "3   11320   3358    0.0\n",
       "4   14027  14024    1.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import BatchNormalization, LSTM, Dense, Input, Conv2D, MaxPooling2D, Flatten, Lambda\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Coursera Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \n",
    "    # tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # conv\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10, 10), \n",
    "                     activation='relu', \n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7, 7), \n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4, 4), \n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4, 4), \n",
    "                     activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, \n",
    "                    activation='sigmoid'))\n",
    "    \n",
    "    # encodings (feature vectors) for the two images\n",
    "    left_encoding = model(left_input)\n",
    "    right_encoding = model(right_input)\n",
    "    \n",
    "    # customized layer to compute the absolute difference between the feature vectors\n",
    "    distance = Lambda(euclidean_distance,\n",
    "                      output_shape=eucl_dist_output_shape)([left_encoding, right_encoding])\n",
    "\n",
    "    \n",
    "    # siamese model connecting the two inputs\n",
    "    siamese_model = Model(inputs=[left_input, right_input], outputs=distance)\n",
    "    \n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/keras-team/keras/blob/master/examples/mnist_siamese.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 105, 105, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 105, 105, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 4096)         38947648    input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           sequential_3[1][0]               \n",
      "                                                                 sequential_3[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 38,947,648\n",
      "Trainable params: 38,947,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = plt.imread(df['filepath'][2]).shape\n",
    "model = get_siamese_model((105,105,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=contrastive_loss, \n",
    "              optimizer='adam', metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Omniglot(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, df, data, batch_size):\n",
    "        self.df = df\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_df = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        anchor = batch_df['anchor'].values\n",
    "        anchor_data = np.array([plt.imread(self.df.iloc[index].filepath) for index in anchor])\n",
    "        item = batch_df['item'].values\n",
    "        item_data = np.array([plt.imread(self.df.iloc[index].filepath) for index in item])\n",
    "        batch_y = batch_df['label'].values\n",
    "        \n",
    "        anchor_data = anchor_data.reshape((anchor_data.shape[0],105,105,1))\n",
    "        item_data = item_data.reshape((item_data.shape[0],105,105,1))\n",
    "        \n",
    "        return [anchor_data, item_data], batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Omniglot(df, data, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.1601 - accuracy: 0.7706\n",
      "Epoch 2/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1542 - accuracy: 0.7836\n",
      "Epoch 3/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.1498 - accuracy: 0.7907\n",
      "Epoch 4/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1485 - accuracy: 0.7918\n",
      "Epoch 5/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1473 - accuracy: 0.7947\n",
      "Epoch 6/100\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.1466 - accuracy: 0.7961\n",
      "Epoch 7/100\n",
      "603/603 [==============================] - 39s 65ms/step - loss: 0.1457 - accuracy: 0.7990\n",
      "Epoch 8/100\n",
      "603/603 [==============================] - 40s 66ms/step - loss: 0.1439 - accuracy: 0.8022\n",
      "Epoch 9/100\n",
      "603/603 [==============================] - 40s 67ms/step - loss: 0.1422 - accuracy: 0.8063\n",
      "Epoch 10/100\n",
      "603/603 [==============================] - 40s 67ms/step - loss: 0.1426 - accuracy: 0.8023\n",
      "Epoch 11/100\n",
      "603/603 [==============================] - 39s 64ms/step - loss: 0.1401 - accuracy: 0.8084\n",
      "Epoch 12/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1381 - accuracy: 0.8106\n",
      "Epoch 13/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1369 - accuracy: 0.8127\n",
      "Epoch 14/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1350 - accuracy: 0.8153\n",
      "Epoch 15/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1347 - accuracy: 0.8180\n",
      "Epoch 16/100\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.1329 - accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1308 - accuracy: 0.8250\n",
      "Epoch 18/100\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.1291 - accuracy: 0.8282\n",
      "Epoch 19/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1264 - accuracy: 0.8309\n",
      "Epoch 20/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1255 - accuracy: 0.8332\n",
      "Epoch 21/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1238 - accuracy: 0.8350\n",
      "Epoch 22/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1232 - accuracy: 0.8373\n",
      "Epoch 23/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1208 - accuracy: 0.8419\n",
      "Epoch 24/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1195 - accuracy: 0.8417\n",
      "Epoch 25/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1179 - accuracy: 0.8454\n",
      "Epoch 26/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1160 - accuracy: 0.8483\n",
      "Epoch 27/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1154 - accuracy: 0.8502\n",
      "Epoch 28/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1152 - accuracy: 0.8513\n",
      "Epoch 29/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1134 - accuracy: 0.8553\n",
      "Epoch 30/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1116 - accuracy: 0.8568\n",
      "Epoch 31/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1097 - accuracy: 0.8592\n",
      "Epoch 32/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1090 - accuracy: 0.8617\n",
      "Epoch 33/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1085 - accuracy: 0.8614\n",
      "Epoch 34/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1075 - accuracy: 0.8663\n",
      "Epoch 35/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1058 - accuracy: 0.8668\n",
      "Epoch 36/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1053 - accuracy: 0.8687\n",
      "Epoch 37/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1043 - accuracy: 0.8694\n",
      "Epoch 38/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1028 - accuracy: 0.8728\n",
      "Epoch 39/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1028 - accuracy: 0.8726\n",
      "Epoch 40/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1022 - accuracy: 0.8748\n",
      "Epoch 41/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1009 - accuracy: 0.8736\n",
      "Epoch 42/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.1002 - accuracy: 0.8745\n",
      "Epoch 43/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.0988 - accuracy: 0.8799\n",
      "Epoch 44/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.0998 - accuracy: 0.8776\n",
      "Epoch 45/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.0992 - accuracy: 0.8792\n",
      "Epoch 46/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.0969 - accuracy: 0.8820\n",
      "Epoch 47/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.0964 - accuracy: 0.8850\n",
      "Epoch 48/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.0966 - accuracy: 0.8854\n",
      "Epoch 49/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.0942 - accuracy: 0.8853\n",
      "Epoch 50/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.0944 - accuracy: 0.8858\n",
      "Epoch 51/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.0937 - accuracy: 0.8907\n",
      "Epoch 52/100\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.0922 - accuracy: 0.8904\n",
      "Epoch 53/100\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.0929 - accuracy: 0.8914\n",
      "Epoch 54/100\n",
      "603/603 [==============================] - 40s 66ms/step - loss: 0.0918 - accuracy: 0.8927\n",
      "Epoch 55/100\n",
      "603/603 [==============================] - 40s 66ms/step - loss: 0.0941 - accuracy: 0.8899\n",
      "Epoch 56/100\n",
      "603/603 [==============================] - 40s 66ms/step - loss: 0.0928 - accuracy: 0.8897\n",
      "Epoch 57/100\n",
      "603/603 [==============================] - 40s 66ms/step - loss: 0.0893 - accuracy: 0.8948\n",
      "Epoch 58/100\n",
      "603/603 [==============================] - 39s 64ms/step - loss: 0.0893 - accuracy: 0.8950\n",
      "Epoch 59/100\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.0891 - accuracy: 0.8951\n",
      "Epoch 60/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.0886 - accuracy: 0.8966\n",
      "Epoch 61/100\n",
      "603/603 [==============================] - 39s 64ms/step - loss: 0.0876 - accuracy: 0.8987\n",
      "Epoch 62/100\n",
      "603/603 [==============================] - 39s 64ms/step - loss: 0.0879 - accuracy: 0.8984\n",
      "Epoch 63/100\n",
      "603/603 [==============================] - 38s 64ms/step - loss: 0.0874 - accuracy: 0.8975\n",
      "Epoch 64/100\n",
      "603/603 [==============================] - 38s 64ms/step - loss: 0.0860 - accuracy: 0.9009\n",
      "Epoch 65/100\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.0855 - accuracy: 0.9005\n",
      "Epoch 66/100\n",
      "603/603 [==============================] - 38s 64ms/step - loss: 0.0856 - accuracy: 0.9003\n",
      "Epoch 67/100\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.0854 - accuracy: 0.9005\n",
      "Epoch 68/100\n",
      "603/603 [==============================] - 39s 65ms/step - loss: 0.0851 - accuracy: 0.9032\n",
      "Epoch 69/100\n",
      "603/603 [==============================] - 38s 64ms/step - loss: 0.0843 - accuracy: 0.9050\n",
      "Epoch 70/100\n",
      "603/603 [==============================] - 40s 66ms/step - loss: 0.0851 - accuracy: 0.9015\n",
      "Epoch 71/100\n",
      "603/603 [==============================] - 40s 66ms/step - loss: 0.0853 - accuracy: 0.9030\n",
      "Epoch 72/100\n",
      "603/603 [==============================] - 38s 64ms/step - loss: 0.0846 - accuracy: 0.9021\n",
      "Epoch 73/100\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.0823 - accuracy: 0.9087\n",
      "Epoch 74/100\n",
      "603/603 [==============================] - 39s 64ms/step - loss: 0.0829 - accuracy: 0.9041\n",
      "Epoch 75/100\n",
      "603/603 [==============================] - 39s 64ms/step - loss: 0.0818 - accuracy: 0.9073\n",
      "Epoch 76/100\n",
      "603/603 [==============================] - 38s 64ms/step - loss: 0.0816 - accuracy: 0.9088\n",
      "Epoch 77/100\n",
      "603/603 [==============================] - 38s 64ms/step - loss: 0.0816 - accuracy: 0.9091\n",
      "Epoch 78/100\n",
      "603/603 [==============================] - 38s 64ms/step - loss: 0.0806 - accuracy: 0.9098\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 38s 63ms/step - loss: 0.0799 - accuracy: 0.9125\n",
      "Epoch 80/100\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.0798 - accuracy: 0.91250s - loss: 0\n",
      "Epoch 81/100\n",
      "603/603 [==============================] - 37s 62ms/step - loss: 0.0789 - accuracy: 0.9146\n",
      "Epoch 82/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0794 - accuracy: 0.9139\n",
      "Epoch 83/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0787 - accuracy: 0.9154\n",
      "Epoch 84/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0801 - accuracy: 0.9134\n",
      "Epoch 85/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0785 - accuracy: 0.9132\n",
      "Epoch 86/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0782 - accuracy: 0.9144\n",
      "Epoch 87/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0775 - accuracy: 0.9142\n",
      "Epoch 88/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0770 - accuracy: 0.9167\n",
      "Epoch 89/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0772 - accuracy: 0.9163\n",
      "Epoch 90/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0778 - accuracy: 0.9167\n",
      "Epoch 91/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0770 - accuracy: 0.9181\n",
      "Epoch 92/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0769 - accuracy: 0.9167\n",
      "Epoch 93/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0758 - accuracy: 0.9186\n",
      "Epoch 94/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0751 - accuracy: 0.9206\n",
      "Epoch 95/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0743 - accuracy: 0.9210\n",
      "Epoch 96/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0753 - accuracy: 0.9213\n",
      "Epoch 97/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0750 - accuracy: 0.9216\n",
      "Epoch 98/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0752 - accuracy: 0.9196\n",
      "Epoch 99/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0746 - accuracy: 0.9231\n",
      "Epoch 100/100\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0739 - accuracy: 0.9208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15dfe1785f8>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"omniglot.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandom(data, df):\n",
    "    a = data.sample()\n",
    "    return plt.imread(df.iloc[a.anchor.item()].filepath).reshape(1,105,105,1), plt.imread(df.iloc[a.item.item()].filepath).reshape(1,105,105,1), a.label.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRandom(data,df, model, threshold):\n",
    "    a = data.sample()\n",
    "    item = plt.imread(df.iloc[a.anchor.item()].filepath).reshape(1,105,105,1)\n",
    "    item2 = plt.imread(df.iloc[a.item.item()].filepath).reshape(1,105,105,1)\n",
    "    label = a.label.item()\n",
    "    f, axarr = plt.subplots(2)\n",
    "\n",
    "    axarr[0].imshow(plt.imread(df.iloc[a.anchor.item()].filepath))\n",
    "    axarr[1].imshow(plt.imread(df.iloc[a.item.item()].filepath))\n",
    "    \n",
    "    if(label == 1):\n",
    "        print(\"Same\")\n",
    "    else:\n",
    "        print(\"Different\")\n",
    "              \n",
    "    prediction = model.predict([item,item2]).item()\n",
    "    print(\"Pred: {}\".format(prediction))\n",
    "    if(prediction < threshold):\n",
    "        print(\"Predicted to be same items\")\n",
    "    else:\n",
    "        print(\"Predicted to be different items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same\n",
      "Pred: 0.6791574358940125\n",
      "Predicted to be same items\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictRandom(data,df, model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
